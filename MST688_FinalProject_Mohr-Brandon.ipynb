{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is my code for the MST688 final project, which will explore a subset of Twitter data attributed to the Russian Internet\n",
    "# Research Agency. The data was collected by Clemson University researchers - Darren Linvill and Patrick Warren.\n",
    "# The comprehensive data set contains every tweet sent from each of the 2,752 handles on the list of data Twitter provided to\n",
    "# Congress in November 2017 since June 19, 2015. In total, the comprehensive data set includes 2,973,371 tweets from\n",
    "#2,848 Twitter handles.\n",
    "\n",
    "# To limit the size of the file for analysis, I only used a subset of the data set, so I downloaded \"IRAhandle_tweets_1.csv\"\n",
    "# from https://www.kaggle.com/fivethirtyeight/russian-troll-tweets and trimmed it down by sorting the \"followers\" column to\n",
    "# any row with more than 5,000 followers (so that the analysis was on the most viewed tweets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to download the data set (which I conveniently uploaded to my Github to avoid having to\n",
    "# log into the provider on Kaggle.com)\n",
    "\n",
    "import pandas\n",
    "\n",
    "data_url = 'https://raw.githubusercontent.com/mohr110/MST688/main/IRAhandle_tweets_1_subset.csv'\n",
    "\n",
    "print(\"Importing data from Github repository...\")\n",
    "IRA_data = pandas.read_csv(data_url, error_bad_lines=False)\n",
    "print(\"Data imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the data set to see the column names\n",
    "IRA_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and how the data frame is set up\n",
    "IRA_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot out the range of when these tweets were posted.\n",
    "# The date column includes the date and the time, but we only want to parse out the date\n",
    "\n",
    "dateList1 = []\n",
    "dateList2 = []\n",
    "\n",
    "dateList1 = IRA_data.publish_date\n",
    "\n",
    "for item in dateList1:\n",
    "    date1 = item.split(\" \")\n",
    "    dateList2.append(date1[0])\n",
    "    \n",
    "# No we have the dates in a list by themselves as integers, let's plot the dates\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "date_counter = Counter(dateList2)\n",
    "\n",
    "date_DF = pandas.DataFrame.from_dict(date_counter, orient='index')\n",
    "date_DF.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Admittedly, this graph is a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do some basic statistics to understand more about the scope of the number of followers these troll accounts had...\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "print(\"The minimum amount of followers is: \", int(min(IRA_data.followers))) # we know this already because I purposely\n",
    "                                                                            # trimmed the data set to rows with 5,000\n",
    "                                                                            # followers or more\n",
    "        \n",
    "print(\"The maximum amount of followers is: \", int(max(IRA_data.followers))) # shows the largest amount of followers in this\n",
    "                                                                            # data subset is 40,788\n",
    "\n",
    "print(\"The average amount of followers is: \", round(mean(IRA_data.followers),2)) # the average amount of followers is ~13,578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that the IRA did not just tweet in English, but what other languages did they tweet in?\n",
    "\n",
    "IRA_data.language.unique() # this shows the amount of languages is fairly large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find out the distribution to see what languages were used most\n",
    "\n",
    "languages = IRA_data.language\n",
    "languages_counter = Counter(languages)\n",
    "\n",
    "language_DF = pandas.DataFrame.from_dict(languages_counter, orient='index')\n",
    "language_DF.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we see 'English' is used by far the most\n",
    "# With 'English' skewing the scale, it is hard to see the other languag metrics...so let's remove 'English' and plot again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_trimmed = []\n",
    "\n",
    "for item in languages:\n",
    "    if item != 'English':\n",
    "        languages_trimmed.append(item)\n",
    "        \n",
    "languages_trimmed_counter = Counter(languages_trimmed)\n",
    "\n",
    "language_trimmed_DF = pandas.DataFrame.from_dict(languages_trimmed_counter, orient='index')\n",
    "language_trimmed_DF.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we see that Russian is the next largest language used, with other languages minimally appearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_trimmed2 = []\n",
    "\n",
    "for item in languages_trimmed:\n",
    "    if item != 'Russian':\n",
    "        languages_trimmed2.append(item)\n",
    "        \n",
    "languages_trimmed_counter2 = Counter(languages_trimmed2)\n",
    "\n",
    "language_trimmed_DF2 = pandas.DataFrame.from_dict(languages_trimmed_counter2, orient='index')\n",
    "language_trimmed_DF2.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we see a better distribution of some of the languages that appear less frequently without 'English' and 'Russian'\n",
    "# skewing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know that the IRA posted divisive content from both sides of the political spectrum, Left and Right...\n",
    "# Let's plot the difference in messaging based on political ideology\n",
    "\n",
    "ideology = []\n",
    "\n",
    "for item in IRA_data.account_type:\n",
    "    if item == 'left':\n",
    "        ideology.append(item)\n",
    "    elif item == 'Right':\n",
    "        ideology.append(item)\n",
    "\n",
    "ideology_counter = Counter(ideology)\n",
    "\n",
    "Left = ideology_counter[\"left\"]\n",
    "Right = ideology_counter[\"Right\"]\n",
    "\n",
    "ideology_DF = pandas.DataFrame.from_dict(ideology_counter, orient='index')\n",
    "ideology_DF.plot(kind=\"pie\",subplots=True)\n",
    "print(\"Left: \",Left)\n",
    "print(\"Right: \",Right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this subset of data (which remember is just a very minimal subset) - most tweets had a left-ideology focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us look at the Tweets themselves and see what insight we can derive by generating a word cloud\n",
    "# The code in this section was derived from GeeksforGeeks at 'https://www.geeksforgeeks.org/generating-word-cloud-python/'\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will show us the list of words that the program removes from the wordcloud before generating so it doesn't show\n",
    "# common words like 'the' or 'and'\n",
    "\n",
    "comment_words = '' \n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this section was derived from GeeksforGeeks at 'https://www.geeksforgeeks.org/generating-word-cloud-python/'\n",
    " \n",
    "# iterate through the data frame\n",
    "for val in IRA_data.content:      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "      \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "  \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the word cloud, we see that there are a lot of random 'words' like \"https\" and \"co\" that are being included when they\n",
    "# don't add much value to the analysis. So we are going to add these 'words' to the word cloud's \"stopwords\"\n",
    "\n",
    "stopwords.add(\"https\")\n",
    "stopwords.add(\"co\")\n",
    "stopwords.add(\"http\")\n",
    "stopwords.add(\"1kpxtnl16oo\")\n",
    "stopwords.add(\"1kpxto2hfw\")\n",
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The code in this section was derived from GeeksforGeeks at 'https://www.geeksforgeeks.org/generating-word-cloud-python/'\n",
    "\n",
    "comment_words = '' \n",
    "  \n",
    "# iterate through the data frame\n",
    "for val in IRA_data.content:      \n",
    "    # typecaste each val to string \n",
    "    val = str(val) \n",
    "  \n",
    "    # split the value \n",
    "    tokens = val.split() \n",
    "      \n",
    "    # Converts each token into lowercase \n",
    "    for i in range(len(tokens)): \n",
    "        tokens[i] = tokens[i].lower() \n",
    "      \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    "  \n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = stopwords, \n",
    "                min_font_size = 10).generate(comment_words) \n",
    "  \n",
    "# plot the WordCloud image                        \n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
